{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e07ea1fb-71cb-4f75-a2fd-eab1e2044a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================== SETUP ==================\n",
    "import os, random, numpy as np, torch, timm\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, confusion_matrix\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4a114368-41fe-464b-8fdb-2cc6149f55d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "# Reproducibility\n",
    "seed = 42\n",
    "random.seed(seed); np.random.seed(seed); torch.manual_seed(seed)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c1f7aeac-85d2-4849-be1a-8a494c947804",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================== PATHS & CONSTANTS ==================\n",
    "data_dir = \"Brain_cancer\"   # your folder path\n",
    "IMG_SIZE = 224\n",
    "BATCH_SIZE = 16\n",
    "EPOCHS = 10\n",
    "LR = 3e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "61c670a8-07f0-44b1-87fb-b29e116cbe05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================== TRANSFORMS ==================\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(IMG_SIZE),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485,0.456,0.406],\n",
    "                         std=[0.229,0.224,0.225])\n",
    "])\n",
    "val_test_transform = transforms.Compose([\n",
    "    transforms.Resize((IMG_SIZE,IMG_SIZE)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485,0.456,0.406],\n",
    "                         std=[0.229,0.224,0.225])\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "54841e7b-cb3a-4533-85a2-2af8d5851fac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes: ['brain_glioma', 'brain_menin', 'brain_tumor']\n",
      "Train: 4239 | Val: 908 | Test: 909\n"
     ]
    }
   ],
   "source": [
    "# ================== DATASET & SPLITS ==================\n",
    "full_dataset = datasets.ImageFolder(root=data_dir)\n",
    "print(\"Classes:\", full_dataset.classes)\n",
    "\n",
    "targets = np.array(full_dataset.targets)\n",
    "indices = np.arange(len(full_dataset))\n",
    "\n",
    "# 70% train, 15% val, 15% test\n",
    "train_idx, temp_idx, y_train, y_temp = train_test_split(\n",
    "    indices, targets, test_size=0.3, stratify=targets, random_state=seed\n",
    ")\n",
    "val_idx, test_idx, y_val, y_test = train_test_split(\n",
    "    temp_idx, y_temp, test_size=0.5, stratify=y_temp, random_state=seed\n",
    ")\n",
    "\n",
    "full_dataset.transform = train_transform\n",
    "train_ds = Subset(full_dataset, train_idx)\n",
    "full_dataset.transform = val_test_transform\n",
    "val_ds = Subset(full_dataset, val_idx)\n",
    "test_ds = Subset(full_dataset, test_idx)\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True, num_workers=4)\n",
    "val_loader = DataLoader(val_ds, batch_size=BATCH_SIZE, shuffle=False, num_workers=4)\n",
    "test_loader = DataLoader(test_ds, batch_size=BATCH_SIZE, shuffle=False, num_workers=4)\n",
    "\n",
    "print(f\"Train: {len(train_ds)} | Val: {len(val_ds)} | Test: {len(test_ds)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "097d6f98-1f9d-48df-8f92-4918260dd054",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================== MODEL (ViT) ==================\n",
    "num_classes = len(full_dataset.classes)\n",
    "model_name = \"vit_base_patch16_224\"  # can change to vit_tiny_patch16_224\n",
    "\n",
    "model = timm.create_model(model_name, pretrained=True, num_classes=num_classes)\n",
    "\n",
    "# Freeze all layers\n",
    "for p in model.parameters():\n",
    "    p.requires_grad = False\n",
    "\n",
    "# Replace classifier head\n",
    "if hasattr(model, \"reset_classifier\"):\n",
    "    model.reset_classifier(num_classes=num_classes)\n",
    "else:\n",
    "    model.head = nn.Linear(model.head.in_features, num_classes)\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "# ================== TRAINING SETUP ==================\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=LR)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', patience=3, factor=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8f87934b-fc44-41ea-af62-b7584570f9e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 [Train]: 100%|█████████████████████| 265/265 [03:04<00:00,  1.44it/s]\n",
      "Epoch 1/10 [Val]: 100%|█████████████████████████| 57/57 [00:57<00:00,  1.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss=0.5197 Acc=0.7941 | Val Loss=0.3580 Acc=0.8711\n",
      "✅ Saved best model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10 [Train]: 100%|█████████████████████| 265/265 [03:03<00:00,  1.45it/s]\n",
      "Epoch 2/10 [Val]: 100%|█████████████████████████| 57/57 [00:57<00:00,  1.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: Train Loss=0.2841 Acc=0.9023 | Val Loss=0.2646 Acc=0.9130\n",
      "✅ Saved best model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10 [Train]: 100%|█████████████████████| 265/265 [03:09<00:00,  1.40it/s]\n",
      "Epoch 3/10 [Val]: 100%|█████████████████████████| 57/57 [00:57<00:00,  1.02s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: Train Loss=0.2292 Acc=0.9210 | Val Loss=0.2259 Acc=0.9196\n",
      "✅ Saved best model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/10 [Train]: 100%|█████████████████████| 265/265 [03:02<00:00,  1.45it/s]\n",
      "Epoch 4/10 [Val]: 100%|█████████████████████████| 57/57 [00:58<00:00,  1.02s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: Train Loss=0.1987 Acc=0.9325 | Val Loss=0.2067 Acc=0.9240\n",
      "✅ Saved best model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/10 [Train]: 100%|█████████████████████| 265/265 [03:05<00:00,  1.42it/s]\n",
      "Epoch 5/10 [Val]: 100%|█████████████████████████| 57/57 [00:58<00:00,  1.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: Train Loss=0.1733 Acc=0.9446 | Val Loss=0.1831 Acc=0.9350\n",
      "✅ Saved best model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/10 [Train]: 100%|█████████████████████| 265/265 [03:03<00:00,  1.44it/s]\n",
      "Epoch 6/10 [Val]: 100%|█████████████████████████| 57/57 [00:58<00:00,  1.02s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: Train Loss=0.1591 Acc=0.9469 | Val Loss=0.1713 Acc=0.9328\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/10 [Train]: 100%|█████████████████████| 265/265 [03:05<00:00,  1.43it/s]\n",
      "Epoch 7/10 [Val]: 100%|█████████████████████████| 57/57 [00:58<00:00,  1.02s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: Train Loss=0.1441 Acc=0.9540 | Val Loss=0.1656 Acc=0.9493\n",
      "✅ Saved best model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/10 [Train]: 100%|█████████████████████| 265/265 [03:04<00:00,  1.44it/s]\n",
      "Epoch 8/10 [Val]: 100%|█████████████████████████| 57/57 [00:57<00:00,  1.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: Train Loss=0.1320 Acc=0.9597 | Val Loss=0.1624 Acc=0.9493\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/10 [Train]: 100%|█████████████████████| 265/265 [03:08<00:00,  1.41it/s]\n",
      "Epoch 9/10 [Val]: 100%|█████████████████████████| 57/57 [00:58<00:00,  1.02s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: Train Loss=0.1250 Acc=0.9601 | Val Loss=0.1456 Acc=0.9438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10 [Train]: 100%|████████████████████| 265/265 [03:06<00:00,  1.42it/s]\n",
      "Epoch 10/10 [Val]: 100%|████████████████████████| 57/57 [00:58<00:00,  1.02s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: Train Loss=0.1152 Acc=0.9641 | Val Loss=0.1393 Acc=0.9548\n",
      "✅ Saved best model\n"
     ]
    }
   ],
   "source": [
    "# ================== TRAINING LOOP ==================\n",
    "best_val_acc = 0.0\n",
    "save_path = \"best_vit_brain_tumor.pth\"\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    total_loss, preds_all, labels_all = 0.0, [], []\n",
    "    for imgs, labels in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{EPOCHS} [Train]\"):\n",
    "        imgs, labels = imgs.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(imgs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item() * imgs.size(0)\n",
    "        preds_all.extend(outputs.argmax(1).cpu().numpy())\n",
    "        labels_all.extend(labels.cpu().numpy())\n",
    "    train_acc = accuracy_score(labels_all, preds_all)\n",
    "    train_loss = total_loss / len(train_ds)\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    val_preds, val_labels, val_loss = [], [], 0.0\n",
    "    with torch.no_grad():\n",
    "        for imgs, labels in tqdm(val_loader, desc=f\"Epoch {epoch+1}/{EPOCHS} [Val]\"):\n",
    "            imgs, labels = imgs.to(device), labels.to(device)\n",
    "            outputs = model(imgs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item() * imgs.size(0)\n",
    "            val_preds.extend(outputs.argmax(1).cpu().numpy())\n",
    "            val_labels.extend(labels.cpu().numpy())\n",
    "    val_acc = accuracy_score(val_labels, val_preds)\n",
    "    val_loss /= len(val_ds)\n",
    "    scheduler.step(val_acc)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}: Train Loss={train_loss:.4f} Acc={train_acc:.4f} | Val Loss={val_loss:.4f} Acc={val_acc:.4f}\")\n",
    "\n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        torch.save(model.state_dict(), save_path)\n",
    "        print(\"✅ Saved best model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bc573a58-5548-4270-bc4f-48e49debb91c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████████████████████████████| 57/57 [00:58<00:00,  1.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== FINAL TEST RESULTS ===\n",
      "Accuracy:  0.9472\n",
      "Precision: 0.9470\n",
      "Recall:    0.9470\n",
      "F1-score:  0.9469\n",
      "Confusion Matrix:\n",
      " [[291  10   0]\n",
      " [ 11 272  17]\n",
      " [  1   9 298]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# ================== EVALUATION ON TEST SET ==================\n",
    "model.load_state_dict(torch.load(save_path, map_location=device))\n",
    "model.eval()\n",
    "\n",
    "y_true, y_pred = [], []\n",
    "with torch.no_grad():\n",
    "    for imgs, labels in tqdm(test_loader, desc=\"Testing\"):\n",
    "        imgs = imgs.to(device)\n",
    "        outputs = model(imgs)\n",
    "        preds = outputs.argmax(1).cpu().numpy()\n",
    "        y_pred.extend(preds)\n",
    "        y_true.extend(labels.numpy())\n",
    "\n",
    "acc = accuracy_score(y_true, y_pred)\n",
    "prec, rec, f1, _ = precision_recall_fscore_support(y_true, y_pred, average='macro')\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "print(\"\\n=== FINAL TEST RESULTS ===\")\n",
    "print(f\"Accuracy:  {acc:.4f}\")\n",
    "print(f\"Precision: {prec:.4f}\")\n",
    "print(f\"Recall:    {rec:.4f}\")\n",
    "print(f\"F1-score:  {f1:.4f}\")\n",
    "print(\"Confusion Matrix:\\n\", cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d30fe4fd-7395-452a-a93d-7ac6339cb3cf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (jp)",
   "language": "python",
   "name": "jp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
